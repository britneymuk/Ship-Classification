{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Ship classification.ipynb","provenance":[],"collapsed_sections":["aAM1bJ239bbb","DsGqVZSxHHK2"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1h14noBbiUUl","executionInfo":{"status":"ok","timestamp":1649580619216,"user_tz":-480,"elapsed":23523,"user":{"displayName":"britney muk","userId":"11561769268916331520"}},"outputId":"83662962-45fe-4bdd-aa49-14f48682a377"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["cd \"/content/drive/MyDrive/deep\""],"metadata":{"id":"8gxDj0GBudxI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os \n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.image as mpimg\n","import torch\n","import torchvision.models as models\n","import torch.nn as nn\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch.utils.data import Dataset, DataLoader \n","import torchvision\n","import torchvision.transforms as transforms\n","from torchsummary import summary\n","from PIL import Image\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt"],"metadata":{"id":"Zn9SSa71jH27"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Helper Function"],"metadata":{"id":"bGb9XLL8fWJp"}},{"cell_type":"code","source":["if not os.path.exists(\"./models\"):\n","    os.mkdir(\"models\")"],"metadata":{"id":"uSe9nSrjfiXD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(net, trainloader, optimizer, scheduler, num_epochs, start_epoch=0):\n","  \n","    # variables\n","    best_val_loss = np.inf\n","    patience = 15\n","    saturate_count = 0\n","    loss_stats = {\n","        'train': [],\n","        \"val\": []\n","    }\n","    if torch.cuda.is_available():\n","      net.cuda()\n","\n","    # train the network\n","    for e in range(start_epoch, num_epochs): \n","        # set to training mode\n","        net.train()   \n","        running_loss = 0.0\n","        running_count = 0.0\n","        for i, (inputs, labels) in enumerate(trainloader):\n","            # Clear all the gradient to 0\n","            optimizer.zero_grad()\n","            # transfer data to GPU\n","            if torch.cuda.is_available():\n","                inputs = inputs.cuda()\n","                labels = labels.cuda()\n","            # forward propagation\n","            outs = net(inputs)\n","            # compute loss \n","            loss = criterion(outs, labels.float())\n","            # backpropagation to get dw\n","            loss.backward()\n","            # update the parameters\n","            optimizer.step()\n","            # get the loss\n","            running_loss += loss.item()\n","            running_count += 1\n","        # compute the averaged loss in each epoch\n","        train_loss = running_loss / running_count\n","        running_loss = 0. \n","        running_count = 0.\n","        # track train loss\n","        loss_stats['train'].append(train_loss)      \n","        # Update the scheduler's counter\n","        scheduler.step()\n","\n","        # set to evaluation mode\n","        net.eval()\n","        for i, (inputs, labels) in enumerate(valloader):\n","            # transfer data to GPU\n","            if torch.cuda.is_available():\n","                inputs = inputs.cuda()\n","                labels = labels.cuda()\n","            # forward propagation\n","            outs = net(inputs)\n","            # compute loss \n","            loss = criterion(outs, labels.float())\n","            # get the loss\n","            running_loss += loss.item()\n","            running_count += 1\n","         # compute the averaged loss in each epoch\n","        val_loss = running_loss / running_count\n","        running_loss = 0. \n","        running_count = 0. \n","        # track validation loss\n","        loss_stats['val'].append(val_loss)\n","\n","        print(f'Epoch {e+1:2d}/{num_epochs:d} : train_loss = {train_loss:.4f}, val_loss = {val_loss:.4f}') \n","\n","        # stop once it converge\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            saturate_count = 0\n","            # saving the best model \n","            checkpoint_file = './models/saved_params.pt'\n","            torch.save({\n","              'epoch': e,\n","              'train_loss': train_loss,\n","              'val_loss': val_loss,\n","              'model_state_dict': net.state_dict(),\n","              'optimizer_state_dict': optimizer.state_dict(),\n","              'scheduler_state_dict': scheduler.state_dict()\n","              }, checkpoint_file)\n","        else:\n","            saturate_count += 1\n","            if saturate_count >= patience:\n","                print('Early stopping!')\n","                return\n","    return loss_stats"],"metadata":{"id":"LkAPvhnxfc0j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate(net, testloader):\n","    \n","    accuracy_stats = []\n","\n","    # set to evaluation mode\n","    net.eval() \n","    # running_correct\n","    running_corrects = 0\n","    running_count = 0\n","    # Repeat for all batch data in the test set\n","    for inputs, targets in testloader:\n","        # transfer to the GPU\n","        if torch.cuda.is_available():\n","            inputs = inputs.cuda()\n","            targets = targets.cuda()\n","\t\n","        # disable gradient computation\n","        with torch.no_grad():\n","            # perform inference\n","            outputs = net(inputs)\n","            # predict as the best result  \n","            _, predicted = torch.max(outputs,1)\n","            _, actual = torch.max(targets,1)\n","            running_corrects += (actual==predicted).double().sum()\n","\n","            accuracy = 100*running_corrects/len(testloader.dataset)\n","            accuracy_stats.append(accuracy.item())\n","\n","    print('Accuracy = {:.2f}%'.format(accuracy))\n","  \n","    return accuracy_stats"],"metadata":{"id":"NSuVLbpqfmxw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Prepare the dataset (.csv) at file level\n","Use the 6252 images as our dataset<br>\n","Dataset-->Train(0.8),Test(0.2)<br>\n","Train-->Train(0.9),Validation(0.1)<br>\n"],"metadata":{"id":"nMtfcMUF5j5y"}},{"cell_type":"code","source":["df = pd.read_csv('./train/train.csv')"],"metadata":{"id":"SS93NUpcA-_l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_size=0.8\n","split_csv=round(len(df)*train_size)\n","print(split_csv)"],"metadata":{"id":"Kee_uW1zYUs6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_file=df[:split_csv]\n","test_file=df[split_csv:]\n","train_file.to_csv('./train/train_file.csv', index=False)\n","test_file.to_csv('./train/test_file.csv', index=False)"],"metadata":{"id":"q4ZTUCd9W8UX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train=pd.read_csv('./train/train_file.csv')\n","df_test=pd.read_csv('./train/test_file.csv')"],"metadata":{"id":"FIhtrhWHZpA9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train.head()"],"metadata":{"id":"9MXJKFMqhBgY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Data Visualization"],"metadata":{"id":"tAyk56_Hfy-k"}},{"cell_type":"code","source":["print('Number of training set:', len(df_train))\n","print('Number of test sample:', len(df_test))"],"metadata":{"id":"tfP-cH9yfycI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ship =['Cargo', 'Military', 'Carrier', 'Cruise', 'Tankers']\n","\n","# display count of ship types\n","fig = sns.countplot(x=train_file['category'].values)\n","fig.set_title('Count of each ship type')\n","fig.set_xlabel('Category')\n","fig.set_xticklabels(ship)\n","plt.show()"],"metadata":{"id":"EEWrFmzAgBLm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# display image\n","idx=4\n","\n","image_name, category= train_file.iloc[idx]\n","imgFile = mpimg.imread('./train/images/{}'.format(image_name))\n","plt.imshow(imgFile)\n","print('Category =',category , ' Ship =', ship[category-1])"],"metadata":{"id":"r4nUVstKgFu8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Create dataset class"],"metadata":{"id":"h9BKKgIT7Htj"}},{"cell_type":"code","source":["class ShipDataset(Dataset):\n","\n","  def __init__(self, filename, transform=None, imgFolder='./train/images'):\n","    CSVfile = pd.read_csv(filename)\n","    self.data = CSVfile['image'].tolist() # get the image name\n","    self.transform = transform\n","    self.imgFolder = imgFolder\n","    ohe = OneHotEncoder(dtype='int8', sparse=False)\n","    self.y = ohe.fit_transform(CSVfile['category'].values.reshape(-1,1)) # encode category\n","\n","  def __len__(self):\n","    return len(self.data)\n","\n","  def __getitem__(self, idx):\n","    # get the image\n","    path = os.path.join(self.imgFolder, self.data[idx])\n","    image = Image.open(path).convert('RGB')\n","\n","    # perform transformation\n","    if self.transform is not None:\n","      image = self.transform(image)\n","\n","    # get the label\n","    label = self.y[idx]\n","\n","    # return sample\n","    return image, label"],"metadata":{"id":"zMwfCd1tlZM8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Augmentations\n","train_transform = transforms.Compose([\n","  transforms.Resize((256,256)),\n","  transforms.RandomCrop(224),\n","  transforms.RandomHorizontalFlip(),\n","  transforms.ToTensor(),\n","  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","test_transform = transforms.Compose([\n","    transforms.Resize((224,224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])"],"metadata":{"id":"axXwjs7jpjrk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 90-10 train-validation split\n","tr, val = train_test_split(train_file.category, stratify=train_file.category, test_size=0.1, random_state=42)\n","train_sampler = SubsetRandomSampler(list(tr.index)) \n","valid_sampler = SubsetRandomSampler(list(val.index))"],"metadata":{"id":"URM3ECVPfhbh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# dataloader\n","BS = 49\n","\n","trainset = ShipDataset('./train/train_file.csv', transform=train_transform)\n","trainloader = DataLoader(trainset, batch_size=BS,sampler=train_sampler,num_workers=2)\n","\n","valset = ShipDataset('./train/train_file.csv', transform=test_transform)\n","valloader =DataLoader(valset, batch_size=BS,sampler=valid_sampler,num_workers=2)"],"metadata":{"id":"t6bFWdFSf56W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x, y = next(iter(trainloader))"],"metadata":{"id":"FYhLygX0waVm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(x.shape)\n","print(y.shape)"],"metadata":{"id":"kR4bHGm0whkq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Train Model"],"metadata":{"id":"8VHDS4Ke9VBZ"}},{"cell_type":"markdown","source":["Efficient Net B0"],"metadata":{"id":"-MkQF_zOw3CR"}},{"cell_type":"code","source":["efficientNet = models.efficientnet_b0(pretrained=True)"],"metadata":{"id":"ANm1dDoc2j-x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["efficientNet"],"metadata":{"id":"J8pOBR8KyS-0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for name,param in efficientNet.named_parameters():\n","  print(name,param.requires_grad)"],"metadata":{"id":"UvESMXgyjzbb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["in_c = efficientNet.classifier[1].in_features  \n","efficientNet.classifier[1] = nn.Sequential(\n","    nn.Linear(in_c, 5),\n","    nn.Softmax(dim = 1)\n",")"],"metadata":{"id":"D6TY8Qk62nqd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" # freeze the layers\n","freeze_layers = [\"features.6\", \"features.7\", \"features.8\", \"fc\"]\n","\n","for name, param in efficientNet.named_parameters():\n","  if any([name.startswith(layer) for layer in freeze_layers]):\n","    param.requires_grad = False "],"metadata":{"id":"eAT8bMzS2qae"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# set up criterion, optimizer, scheduler\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(efficientNet.parameters(), lr=0.01, momentum=0.9)\n","scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"],"metadata":{"id":"Yydx4y36AjmG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["efficient_train_loss = train(efficientNet, trainloader, optimizer, scheduler, num_epochs=15)"],"metadata":{"id":"PQXz3M0h4zWy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Resnet 152"],"metadata":{"id":"vouuVHv1xEp7"}},{"cell_type":"code","source":["resnet152 = models.resnet152(pretrained= True)"],"metadata":{"id":"A4ZnRM7Gvbhn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["resnet152"],"metadata":{"id":"O_eaIL1PxPv6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for name,param in resnet152.named_parameters():\n","  print(name,param.requires_grad)"],"metadata":{"id":"-cdGTAOjjisX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["in_c = resnet152.fc.in_features  \n","resnet152.fc = nn.Sequential(\n","    nn.Linear(in_c, 5),\n","    nn.Softmax(dim = 1)\n",")"],"metadata":{"id":"Fxcxzf3cyLpf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# set up criterion, optimizer, scheduler\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(resnet152.parameters(), lr=0.01, momentum=0.9)\n","scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"],"metadata":{"id":"-FZbhmCmymYr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["resnet_train_loss = train(resnet152, trainloader, optimizer, scheduler, num_epochs=15)"],"metadata":{"id":"RWD3VL0rytz_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Resume Training (if needed)"],"metadata":{"id":"aAM1bJ239bbb"}},{"cell_type":"code","source":["# # load the checkpoint file\n","# checkpoint = torch.load('./models/saved_params.pt')\n","# model_conv.load_state_dict(checkpoint['model_state_dict'])\n","# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","# scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n","# previous_epoch = checkpoint['epoch']\n","# previous_train_loss = checkpoint['train_loss']\n","# previous_val_loss = checkpoint['val_loss']\n","\n","# # resume training\n","# print(f'Resuming previous epoch. Last run epoch: {previous_epoch+1}, train loss: {previous_train_loss:.4f}, validation loss: {previous_val_loss:.4f}')\n","# train (model_conv, trainloader, optimizer, scheduler, num_epochs=30, start_epoch=previous_epoch+1)"],"metadata":{"id":"yGJ-fZ_BVI8I"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Load Model (if needed)"],"metadata":{"id":"DsGqVZSxHHK2"}},{"cell_type":"code","source":["# model_conv = torch.load(\"./models/saved_model.pt\")"],"metadata":{"id":"SKKSgkS3G8cK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Evaluation"],"metadata":{"id":"OlxEIuw1VKFd"}},{"cell_type":"code","source":["# dataloader\n","testset = ShipDataset('./train/test_file.csv', transform=test_transform)\n","testloader = DataLoader(testset, batch_size=BS,num_workers=2)"],"metadata":{"id":"2r25kEaBmWW6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["efficient_accuracy = evaluate(efficientNet, testloader)"],"metadata":{"id":"tp4WfASdMiAe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["resnet152_accuracy = evaluate(resnet152, testloader)"],"metadata":{"id":"DYGGwJiAy6pn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# save your best model <3\n","# torch.save(efficientNet, \"./models/saved_model_efficientNet.pt\")"],"metadata":{"id":"0vZ0_-jTGXuD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train Loss Graph\n","\n","# plt.plot(efficient_train_loss[\"train\"], label='Efficient Net')\n","plt.plot(resnet_train_loss[\"train\"], label='Resnet152')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"x4QU-Hf84hhL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(efficient_train_loss[\"val\"], label='Efficient Net')\n","plt.plot(resnet_train_loss[\"val\"], label='Resnet152')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"DXOhg_hMDO2q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(efficient_accuracy, label='Efficient Net')\n","plt.plot(resnet152_accuracy, label='Resnet152')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"-HXqVuGNEdHe"},"execution_count":null,"outputs":[]}]}